{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow-federated\n",
      "Version: 0.17.0\n",
      "Summary: TensorFlow Federated is an open-source federated learning framework.\n",
      "Home-page: http://tensorflow.org/federated\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\flc\\anaconda3\\envs\\federated\\lib\\site-packages\n",
      "Requires: absl-py, attrs, cachetools, dm-tree, grpcio, h5py, numpy, portpicker, retrying, semantic-version, tensorflow, tensorflow-addons, tensorflow-model-optimization, tensorflow-privacy\n",
      "Required-by: \n",
      "c:\\Users\\flc\\Anaconda3\\envs\\federated\\python.exe\n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow-federated\n",
    "import sys\n",
    "print(sys.executable)  # Prints the path to the Python executable being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown optimizer: Custom>Adam",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 125\u001b[0m\n\u001b[0;32m    122\u001b[0m     plot_cka_cdf(cka_matrix_before)\n\u001b[0;32m    123\u001b[0m     plot_cka_cdf(cka_matrix_after)\n\u001b[1;32m--> 125\u001b[0m \u001b[43mperform_cka_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 108\u001b[0m, in \u001b[0;36mperform_cka_analysis\u001b[1;34m(model_paths, data)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_cka_analysis\u001b[39m(model_paths, data):\n\u001b[1;32m--> 108\u001b[0m     models \u001b[38;5;241m=\u001b[39m \u001b[43mload_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_paths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m     cka_matrix_before \u001b[38;5;241m=\u001b[39m compute_full_cka_matrix(models, data)\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m# Federated training\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 17\u001b[0m, in \u001b[0;36mload_models\u001b[1;34m(model_paths)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_models\u001b[39m(model_paths):\n\u001b[0;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load all models from given paths, recognizing custom optimizer.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [load_model(path, custom_objects\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomAdam\u001b[39m\u001b[38;5;124m'\u001b[39m: CustomAdam}) \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m model_paths]\n",
      "Cell \u001b[1;32mIn[5], line 17\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_models\u001b[39m(model_paths):\n\u001b[0;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load all models from given paths, recognizing custom optimizer.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCustomAdam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mCustomAdam\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m model_paths]\n",
      "File \u001b[1;32mc:\\Users\\flc\\Anaconda3\\envs\\federated\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py:182\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m generic_utils\u001b[38;5;241m.\u001b[39mCustomObjectScope(custom_objects \u001b[38;5;129;01mor\u001b[39;00m {}):\n\u001b[0;32m    180\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (h5py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    181\u001b[0m       \u001b[38;5;28misinstance\u001b[39m(filepath, h5py\u001b[38;5;241m.\u001b[39mFile) \u001b[38;5;129;01mor\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mis_hdf5(filepath))):\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhdf5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m   filepath \u001b[38;5;241m=\u001b[39m path_to_string(filepath)\n\u001b[0;32m    185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, six\u001b[38;5;241m.\u001b[39mstring_types):\n",
      "File \u001b[1;32mc:\\Users\\flc\\Anaconda3\\envs\\federated\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py:193\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    190\u001b[0m training_config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(training_config\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# Compile model.\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43msaving_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_args_from_training_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    195\u001b[0m saving_utils\u001b[38;5;241m.\u001b[39mtry_build_compiled_arguments(model)\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# Set optimizer weights.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\flc\\Anaconda3\\envs\\federated\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saving_utils.py:211\u001b[0m, in \u001b[0;36mcompile_args_from_training_config\u001b[1;34m(training_config, custom_objects)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m generic_utils\u001b[38;5;241m.\u001b[39mCustomObjectScope(custom_objects):\n\u001b[0;32m    210\u001b[0m   optimizer_config \u001b[38;5;241m=\u001b[39m training_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_config\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 211\u001b[0m   optimizer \u001b[38;5;241m=\u001b[39m \u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m   \u001b[38;5;66;03m# Recover losses.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\flc\\Anaconda3\\envs\\federated\\lib\\site-packages\\tensorflow\\python\\keras\\optimizers.py:865\u001b[0m, in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m all_classes:\n\u001b[0;32m    864\u001b[0m   config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m--> 865\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptimizer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\flc\\Anaconda3\\envs\\federated\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:346\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(identifier, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    344\u001b[0m   \u001b[38;5;66;03m# In this case we are dealing with a Keras config dictionary.\u001b[39;00m\n\u001b[0;32m    345\u001b[0m   config \u001b[38;5;241m=\u001b[39m identifier\n\u001b[1;32m--> 346\u001b[0m   (\u001b[38;5;28mcls\u001b[39m, cls_config) \u001b[38;5;241m=\u001b[39m \u001b[43mclass_and_config_for_serialized_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m      \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom_config\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    350\u001b[0m     arg_spec \u001b[38;5;241m=\u001b[39m tf_inspect\u001b[38;5;241m.\u001b[39mgetfullargspec(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_config)\n",
      "File \u001b[1;32mc:\\Users\\flc\\Anaconda3\\envs\\federated\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:296\u001b[0m, in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[1;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m get_registered_object(class_name, custom_objects, module_objects)\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 296\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m printable_module_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m class_name)\n\u001b[0;32m    298\u001b[0m cls_config \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    299\u001b[0m \u001b[38;5;66;03m# Check if `cls_config` is a list. If it is a list, return the class and the\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;66;03m# associated class configs for recursively deserialization. This case will\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;66;03m# happen on the old version of sequential model (e.g. `keras_version` ==\u001b[39;00m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;66;03m# \"2.0.6\"), which is serialized in a different structure, for example\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;66;03m# \"{'class_name': 'Sequential',\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;66;03m#   'config': [{'class_name': 'Embedding', 'config': ...}, {}, ...]}\".\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown optimizer: Custom>Adam"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "tff.backends.reference.set_reference_context()\n",
    "\n",
    "class CustomAdam(tf.keras.optimizers.Adam):\n",
    "    def __init__(self, name=\"CustomAdam\", **kwargs):\n",
    "        super(CustomAdam, self).__init__(name=name, **kwargs)\n",
    "\n",
    "def load_models(model_paths):\n",
    "    \"\"\"Load all models from given paths, recognizing custom optimizer.\"\"\"\n",
    "    return [load_model(path, custom_objects={'CustomAdam': CustomAdam}) for path in model_paths]\n",
    "\n",
    "def create_federated_data(models, data):\n",
    "    \"\"\"Simulate federated data setup, assuming equal distribution of data across models.\"\"\"\n",
    "    client_data = collections.OrderedDict()\n",
    "    for idx in range(len(models)):\n",
    "        client_data[str(idx)] = data  # Simulate data partitioning\n",
    "    return tff.simulation.FromTensorSlicesClientData(client_data)\n",
    "\n",
    "def create_federated_model(model, example_data):\n",
    "    \"\"\"Wrap a Keras model for use with TFF.\"\"\"\n",
    "    return tff.learning.from_keras_model(\n",
    "        model,\n",
    "        input_spec=example_data.element_spec,\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "def federated_training(federated_data, model, num_rounds=5):\n",
    "    \"\"\"Train using Federated Averaging.\"\"\"\n",
    "    def model_fn():\n",
    "        return create_federated_model(model)\n",
    "    \n",
    "    iterative_process = tff.learning.build_federated_averaging_process(\n",
    "        model_fn,\n",
    "        client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02))\n",
    "    state = iterative_process.initialize()\n",
    "    \n",
    "    for _ in range(num_rounds):\n",
    "        state, metrics = iterative_process.next(state, federated_data)\n",
    "        print(f'Round {_}, Metrics: {metrics}')\n",
    "    \n",
    "    return tff.learning.keras_utils.from_tff_to_keras(state.model)\n",
    "\n",
    "def gram_matrix(X):\n",
    "    \"\"\"Calculate the Gram matrix from layer activations.\"\"\"\n",
    "    n = X.shape[0]\n",
    "    X = X - X.mean(axis=0)\n",
    "    return X @ X.T / n\n",
    "\n",
    "def cka(G, H):\n",
    "    \"\"\"Compute the CKA metric.\"\"\"\n",
    "    return np.trace(G @ H) / np.sqrt(np.trace(G @ G) * np.trace(H @ H))\n",
    "\n",
    "def compute_cka(model1, model2, data):\n",
    "    \"\"\"Compute the CKA between layers of two models using data.\"\"\"\n",
    "    intermediate_model1 = tf.keras.Model(inputs=model1.input, outputs=[layer.output for layer in model1.layers])\n",
    "    intermediate_model2 = tf.keras.Model(inputs=model2.input, outputs=[layer.output for layer in model2.layers])\n",
    "    activations1 = intermediate_model1(data)\n",
    "    activations2 = intermediate_model2(data)\n",
    "    return np.mean([cka(gram_matrix(np.array(act1)), gram_matrix(np.array(act2))) for act1, act2 in zip(activations1, activations2)])\n",
    "\n",
    "def compute_full_cka_matrix(models, data):\n",
    "    \"\"\"Compute the full CKA matrix for a list of models.\"\"\"\n",
    "    n = len(models)\n",
    "    cka_matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            if i == j:\n",
    "                cka_matrix[i, j] = 1.0\n",
    "            else:\n",
    "                cka_matrix[i, j] = cka_matrix[j, i] = compute_cka(models[i], models[j], data)\n",
    "    return cka_matrix\n",
    "\n",
    "def plot_cka_heatmap(cka_matrix, model_names):\n",
    "    \"\"\"Plot a CKA similarity heatmap.\"\"\"\n",
    "    sns.set(style=\"white\")\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    ax = sns.heatmap(cka_matrix, annot=False, fmt=\".2f\", cmap=\"coolwarm_r\",\n",
    "                     xticklabels=[int(item[0])+1 if item else '' for item in model_names],\n",
    "                     yticklabels=[int(item[0])+1 if item else '' for item in model_names],\n",
    "                     square=True, linewidths=.5, cbar_kws={\"shrink\": .8})\n",
    "    ax.set_xlabel('Orbital Planes')\n",
    "    ax.set_ylabel('Orbital Planes')\n",
    "    plt.savefig('./FL/CKA.png', bbox_inches='tight', dpi=500)\n",
    "    plt.show()\n",
    "\n",
    "def plot_cka_cdf(cka_matrix):\n",
    "    \"\"\"Plot the cumulative distribution function (CDF) of the CKA values.\"\"\"\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cka_values = cka_matrix[np.triu_indices_from(cka_matrix, k=1)]\n",
    "    sorted_values = np.sort(cka_values)\n",
    "    plt.step(sorted_values, np.linspace(0, 1, len(sorted_values), endpoint=False), where='post')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.xlabel('CKA Value')\n",
    "    plt.ylabel('CDF')\n",
    "    plt.savefig('./FL/CKA_CDF.png', bbox_inches='tight', dpi=500)\n",
    "    plt.show()\n",
    "\n",
    "def perform_cka_analysis(model_paths, data):\n",
    "    models = load_models(model_paths)\n",
    "    cka_matrix_before = compute_full_cka_matrix(models, data)\n",
    "\n",
    "    # Federated training\n",
    "    federated_data = create_federated_data(models, data)\n",
    "    trained_model = federated_training(federated_data, models[0])\n",
    "    models_after_fl = [trained_model for _ in models]  # Simulate all models updated\n",
    "    cka_matrix_after = compute_full_cka_matrix(models_after_fl, data)\n",
    "\n",
    "    # Extract model identifiers from paths\n",
    "    model_names = [path.split('/')[-1].split('qNetwork')[0].rstrip('_') for path in model_paths]\n",
    "\n",
    "    plot_cka_heatmap(cka_matrix_before, model_names)\n",
    "    plot_cka_heatmap(cka_matrix_after, model_names)\n",
    "    plot_cka_cdf(cka_matrix_before)\n",
    "    plot_cka_cdf(cka_matrix_after)\n",
    "\n",
    "perform_cka_analysis(model_paths, test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./NNs_8GTs_1s_con/0_0qNetwork_8GTs.h5', './NNs_8GTs_1s_con/0_1qNetwork_8GTs.h5', './NNs_8GTs_1s_con/0_2qNetwork_8GTs.h5', './NNs_8GTs_1s_con/0_3qNetwork_8GTs.h5', './NNs_8GTs_1s_con/0_4qNetwork_8GTs.h5', './NNs_8GTs_1s_con/0_5qNetwork_8GTs.h5', './NNs_8GTs_1s_con/0_6qNetwork_8GTs.h5', './NNs_8GTs_1s_con/0_7qNetwork_8GTs.h5', './NNs_8GTs_1s_con/0_8qNetwork_8GTs.h5', './NNs_8GTs_1s_con/0_9qNetwork_8GTs.h5', './NNs_8GTs_1s_con/0_10qNetwork_8GTs.h5', './NNs_8GTs_1s_con/0_11qNetwork_8GTs.h5', './NNs_8GTs_1s_con/0_12qNetwork_8GTs.h5', './NNs_8GTs_1s_con/0_13qNetwork_8GTs.h5', './NNs_8GTs_1s_con/0_14qNetwork_8GTs.h5', './NNs_8GTs_1s_con/0_15qNetwork_8GTs.h5', './NNs_8GTs_1s_con/0_16qNetwork_8GTs.h5', './NNs_8GTs_1s_con/0_17qNetwork_8GTs.h5', './NNs_8GTs_1s_con/0_18qNetwork_8GTs.h5', './NNs_8GTs_1s_con/0_19qNetwork_8GTs.h5', './NNs_8GTs_1s_con/1_0qNetwork_8GTs.h5', './NNs_8GTs_1s_con/1_1qNetwork_8GTs.h5', './NNs_8GTs_1s_con/1_2qNetwork_8GTs.h5', './NNs_8GTs_1s_con/1_3qNetwork_8GTs.h5', './NNs_8GTs_1s_con/1_4qNetwork_8GTs.h5', './NNs_8GTs_1s_con/1_5qNetwork_8GTs.h5', './NNs_8GTs_1s_con/1_6qNetwork_8GTs.h5', './NNs_8GTs_1s_con/1_7qNetwork_8GTs.h5', './NNs_8GTs_1s_con/1_8qNetwork_8GTs.h5', './NNs_8GTs_1s_con/1_9qNetwork_8GTs.h5', './NNs_8GTs_1s_con/1_10qNetwork_8GTs.h5', './NNs_8GTs_1s_con/1_11qNetwork_8GTs.h5', './NNs_8GTs_1s_con/1_12qNetwork_8GTs.h5', './NNs_8GTs_1s_con/1_13qNetwork_8GTs.h5', './NNs_8GTs_1s_con/1_14qNetwork_8GTs.h5', './NNs_8GTs_1s_con/1_15qNetwork_8GTs.h5', './NNs_8GTs_1s_con/1_16qNetwork_8GTs.h5', './NNs_8GTs_1s_con/1_17qNetwork_8GTs.h5', './NNs_8GTs_1s_con/1_18qNetwork_8GTs.h5', './NNs_8GTs_1s_con/1_19qNetwork_8GTs.h5', './NNs_8GTs_1s_con/2_0qNetwork_8GTs.h5', './NNs_8GTs_1s_con/2_1qNetwork_8GTs.h5', './NNs_8GTs_1s_con/2_2qNetwork_8GTs.h5', './NNs_8GTs_1s_con/2_3qNetwork_8GTs.h5', './NNs_8GTs_1s_con/2_4qNetwork_8GTs.h5', './NNs_8GTs_1s_con/2_5qNetwork_8GTs.h5', './NNs_8GTs_1s_con/2_6qNetwork_8GTs.h5', './NNs_8GTs_1s_con/2_7qNetwork_8GTs.h5', './NNs_8GTs_1s_con/2_8qNetwork_8GTs.h5', './NNs_8GTs_1s_con/2_9qNetwork_8GTs.h5', './NNs_8GTs_1s_con/2_10qNetwork_8GTs.h5', './NNs_8GTs_1s_con/2_11qNetwork_8GTs.h5', './NNs_8GTs_1s_con/2_12qNetwork_8GTs.h5', './NNs_8GTs_1s_con/2_13qNetwork_8GTs.h5', './NNs_8GTs_1s_con/2_14qNetwork_8GTs.h5', './NNs_8GTs_1s_con/2_15qNetwork_8GTs.h5', './NNs_8GTs_1s_con/2_16qNetwork_8GTs.h5', './NNs_8GTs_1s_con/2_17qNetwork_8GTs.h5', './NNs_8GTs_1s_con/2_18qNetwork_8GTs.h5', './NNs_8GTs_1s_con/2_19qNetwork_8GTs.h5', './NNs_8GTs_1s_con/3_0qNetwork_8GTs.h5', './NNs_8GTs_1s_con/3_1qNetwork_8GTs.h5', './NNs_8GTs_1s_con/3_2qNetwork_8GTs.h5', './NNs_8GTs_1s_con/3_3qNetwork_8GTs.h5', './NNs_8GTs_1s_con/3_4qNetwork_8GTs.h5', './NNs_8GTs_1s_con/3_5qNetwork_8GTs.h5', './NNs_8GTs_1s_con/3_6qNetwork_8GTs.h5', './NNs_8GTs_1s_con/3_7qNetwork_8GTs.h5', './NNs_8GTs_1s_con/3_8qNetwork_8GTs.h5', './NNs_8GTs_1s_con/3_9qNetwork_8GTs.h5', './NNs_8GTs_1s_con/3_10qNetwork_8GTs.h5', './NNs_8GTs_1s_con/3_11qNetwork_8GTs.h5', './NNs_8GTs_1s_con/3_12qNetwork_8GTs.h5', './NNs_8GTs_1s_con/3_13qNetwork_8GTs.h5', './NNs_8GTs_1s_con/3_14qNetwork_8GTs.h5', './NNs_8GTs_1s_con/3_15qNetwork_8GTs.h5', './NNs_8GTs_1s_con/3_16qNetwork_8GTs.h5', './NNs_8GTs_1s_con/3_17qNetwork_8GTs.h5', './NNs_8GTs_1s_con/3_18qNetwork_8GTs.h5', './NNs_8GTs_1s_con/3_19qNetwork_8GTs.h5', './NNs_8GTs_1s_con/4_0qNetwork_8GTs.h5', './NNs_8GTs_1s_con/4_1qNetwork_8GTs.h5', './NNs_8GTs_1s_con/4_2qNetwork_8GTs.h5', './NNs_8GTs_1s_con/4_3qNetwork_8GTs.h5', './NNs_8GTs_1s_con/4_4qNetwork_8GTs.h5', './NNs_8GTs_1s_con/4_5qNetwork_8GTs.h5', './NNs_8GTs_1s_con/4_6qNetwork_8GTs.h5', './NNs_8GTs_1s_con/4_7qNetwork_8GTs.h5', './NNs_8GTs_1s_con/4_8qNetwork_8GTs.h5', './NNs_8GTs_1s_con/4_9qNetwork_8GTs.h5', './NNs_8GTs_1s_con/4_10qNetwork_8GTs.h5', './NNs_8GTs_1s_con/4_11qNetwork_8GTs.h5', './NNs_8GTs_1s_con/4_12qNetwork_8GTs.h5', './NNs_8GTs_1s_con/4_13qNetwork_8GTs.h5', './NNs_8GTs_1s_con/4_14qNetwork_8GTs.h5', './NNs_8GTs_1s_con/4_15qNetwork_8GTs.h5', './NNs_8GTs_1s_con/4_16qNetwork_8GTs.h5', './NNs_8GTs_1s_con/4_17qNetwork_8GTs.h5', './NNs_8GTs_1s_con/4_18qNetwork_8GTs.h5', './NNs_8GTs_1s_con/4_19qNetwork_8GTs.h5', './NNs_8GTs_1s_con/5_0qNetwork_8GTs.h5', './NNs_8GTs_1s_con/5_1qNetwork_8GTs.h5', './NNs_8GTs_1s_con/5_2qNetwork_8GTs.h5', './NNs_8GTs_1s_con/5_3qNetwork_8GTs.h5', './NNs_8GTs_1s_con/5_4qNetwork_8GTs.h5', './NNs_8GTs_1s_con/5_5qNetwork_8GTs.h5', './NNs_8GTs_1s_con/5_6qNetwork_8GTs.h5', './NNs_8GTs_1s_con/5_7qNetwork_8GTs.h5', './NNs_8GTs_1s_con/5_8qNetwork_8GTs.h5', './NNs_8GTs_1s_con/5_9qNetwork_8GTs.h5', './NNs_8GTs_1s_con/5_10qNetwork_8GTs.h5', './NNs_8GTs_1s_con/5_11qNetwork_8GTs.h5', './NNs_8GTs_1s_con/5_12qNetwork_8GTs.h5', './NNs_8GTs_1s_con/5_13qNetwork_8GTs.h5', './NNs_8GTs_1s_con/5_14qNetwork_8GTs.h5', './NNs_8GTs_1s_con/5_15qNetwork_8GTs.h5', './NNs_8GTs_1s_con/5_16qNetwork_8GTs.h5', './NNs_8GTs_1s_con/5_17qNetwork_8GTs.h5', './NNs_8GTs_1s_con/5_18qNetwork_8GTs.h5', './NNs_8GTs_1s_con/5_19qNetwork_8GTs.h5', './NNs_8GTs_1s_con/6_0qNetwork_8GTs.h5', './NNs_8GTs_1s_con/6_1qNetwork_8GTs.h5', './NNs_8GTs_1s_con/6_2qNetwork_8GTs.h5', './NNs_8GTs_1s_con/6_3qNetwork_8GTs.h5', './NNs_8GTs_1s_con/6_4qNetwork_8GTs.h5', './NNs_8GTs_1s_con/6_5qNetwork_8GTs.h5', './NNs_8GTs_1s_con/6_6qNetwork_8GTs.h5', './NNs_8GTs_1s_con/6_7qNetwork_8GTs.h5', './NNs_8GTs_1s_con/6_8qNetwork_8GTs.h5', './NNs_8GTs_1s_con/6_9qNetwork_8GTs.h5', './NNs_8GTs_1s_con/6_10qNetwork_8GTs.h5', './NNs_8GTs_1s_con/6_11qNetwork_8GTs.h5', './NNs_8GTs_1s_con/6_12qNetwork_8GTs.h5', './NNs_8GTs_1s_con/6_13qNetwork_8GTs.h5', './NNs_8GTs_1s_con/6_14qNetwork_8GTs.h5', './NNs_8GTs_1s_con/6_15qNetwork_8GTs.h5', './NNs_8GTs_1s_con/6_16qNetwork_8GTs.h5', './NNs_8GTs_1s_con/6_17qNetwork_8GTs.h5', './NNs_8GTs_1s_con/6_18qNetwork_8GTs.h5', './NNs_8GTs_1s_con/6_19qNetwork_8GTs.h5']\n",
      "Sample data shape: (100, 28)\n",
      "Sample data: [[ 5.          3.          0.          2.          0.67824614 -0.15959709\n",
      "   8.         10.          6.          9.         -0.40714595 -0.98429741\n",
      "   7.          0.          6.         10.          0.17786105 -1.2564602\n",
      "   0.          5.          1.          0.         -0.19042095  1.30924928\n",
      "   0.60173286 17.74929065  1.16526218 -1.14877182]\n",
      " [ 0.          0.         10.          6.          0.83984602 -1.98125241\n",
      "   0.         10.          4.          9.          0.8934543  -0.58755473\n",
      "   0.          0.          9.          0.         -0.67148795  1.18902811\n",
      "   5.          5.          6.          0.         -1.99258709  1.15001013\n",
      "   1.44556944 14.38145625 -0.93728959  1.80705486]\n",
      " [ 0.         10.          0.          6.         -1.24829754 -1.16792958\n",
      "  10.          0.          0.          2.         -1.5168377  -1.24242709\n",
      "   6.          0.          5.          6.          0.46370002  1.45674041\n",
      "   5.          6.          7.          5.         -1.60796004 -1.45665278\n",
      "   6.01918391  9.80007938  0.56684557  1.58188428]\n",
      " [ 1.         10.          0.          0.          0.53702547  0.84894017\n",
      "  10.          0.          0.          1.         -0.38486216 -0.81537873\n",
      "   6.          0.          6.          1.         -1.77400067  0.13065849\n",
      "  10.         10.          0.          9.          0.06054321  0.73781086\n",
      "   5.19356037 15.56675826  0.03140793 -1.61957008]\n",
      " [ 0.          8.          3.          0.          1.18641299  0.13196282\n",
      "  10.         10.          4.          9.         -1.58372184  1.52710212\n",
      "   6.         10.          3.         10.         -1.84301238 -0.91012108\n",
      "   0.          8.          4.          2.         -0.76997017 -1.00257339\n",
      "   6.82993761 15.19752755 -1.53057039  1.80953286]]\n"
     ]
    }
   ],
   "source": [
    "# Divergencia de modelos\n",
    "# Fedavg post prodcesado sacar nueva cka\n",
    "# cdf: Nothing, model anticipation, plane FL, global FL\n",
    "# average del plano y average total\n",
    "# simulacion despues de fedavg check capabilities\n",
    "# fed CDF\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "def generate_test_data(num_samples, include_not_avail=False):\n",
    "    data = []\n",
    "    queue_values = np.arange(0, 11)  # Possible queue values from 0 to 10\n",
    "    # Set probabilities: 0 at 35%, 10 at 20%, and 5% each for values 1-9\n",
    "    queue_probs = [0.35] + [0.05] * 9 + [0.20]\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        sample = []\n",
    "        # Queue Scores for each direction: Up, Down, Right, Left (4 scores each)\n",
    "        for _ in range(4):\n",
    "            # Queue scores biased towards 0 and 10\n",
    "            sample.extend(np.random.choice(queue_values, 4, p=queue_probs))\n",
    "            \n",
    "            # Relative positions for each direction: latitude and longitude\n",
    "            sample.append(np.random.uniform(-2, 2))  # Latitude relative position\n",
    "            sample.append(np.random.uniform(-2, 2))  # Longitude relative position\n",
    "        \n",
    "        # Absolute positions\n",
    "        sample.append(np.random.uniform(0, 9))  # Absolute latitude normalized\n",
    "        sample.append(np.random.uniform(0, 18))  # Absolute longitude normalized\n",
    "        \n",
    "        # Destination differential coordinates\n",
    "        sample.append(np.random.uniform(-2, 2))  # Destination differential latitude\n",
    "        sample.append(np.random.uniform(-2, 2))  # Destination differential longitude\n",
    "        \n",
    "        # Optionally include not available values\n",
    "        if include_not_avail and np.random.rand() < 0.1:  # 10% chance to introduce a -1 value\n",
    "            idx_to_replace = np.random.choice(len(sample), int(0.1 * len(sample)), replace=False)\n",
    "            sample[idx_to_replace] = -1\n",
    "        \n",
    "        data.append(sample)\n",
    "    \n",
    "    return np.array(data)\n",
    "\n",
    "def get_model_paths(folder, nGTs):\n",
    "    # Create an empty list to hold all file paths\n",
    "    model_files = []\n",
    "    \n",
    "    # Iterate over the range of first and second digit as specified\n",
    "    for i in range(7):  # from 0 to 6\n",
    "        for j in range(20):  # from 0 to 19\n",
    "            # Construct the pattern for each file\n",
    "            pattern = os.path.join(folder, f\"{i}_{j}qNetwork_{nGTs}GTs.h5\")\n",
    "            # Use glob to find files matching the current pattern\n",
    "            files = glob.glob(pattern)\n",
    "            # Add found files to the list\n",
    "            model_files.extend(files)\n",
    "    \n",
    "    # Sort the files to maintain a consistent order\n",
    "    # model_files.sort()\n",
    "    \n",
    "    return model_files\n",
    "\n",
    "# Model paths\n",
    "nGTs = 8\n",
    "secs = 1\n",
    "con  = 'con'    # ['nocon' (no congestion), 'con' (congestion)]\n",
    "folder_path = f'./NNs_{nGTs}GTs_{secs}s_{con}/'\n",
    "model_paths = get_model_paths(folder_path, nGTs)\n",
    "print(model_paths)\n",
    "\n",
    "# Generate dataset\n",
    "num_samples = 100  # Number of state vectors to generate\n",
    "test_data = generate_test_data(num_samples)\n",
    "\n",
    "print(\"Sample data shape:\", test_data.shape)\n",
    "print(\"Sample data:\", test_data[:5])  # Print the first 5 samples to check\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "federated",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
