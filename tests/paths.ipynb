{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import os\n",
    "\n",
    "\n",
    "# Following is added due to incompatibility issues of numba with Python version > 3.7\n",
    "class BlocksForPickle:\n",
    "    def __init__(self, block):\n",
    "        self.size = 64800  # size in bits\n",
    "        self.ID = block.ID  # a string which holds the source id, destination id, and index of the block, e.g. \"1_2_12\"\n",
    "        self.timeAtFull = block.timeAtFull  # the simulation time at which the block was full and was ready to be sent.\n",
    "        self.creationTime = block.creationTime  # the simulation time at which the block was created.\n",
    "        self.timeAtFirstTransmission = block.timeAtFirstTransmission  # the simulation time at which the block left the GT.\n",
    "        self.checkPoints = block.checkPoints  # list of simulation reception times at node with the first entry being the reception time at first sat - can be expanded to include the sat IDs at each checkpoint\n",
    "        self.checkPointsSend = block.checkPointsSend  # list of times after the block was sent at each node\n",
    "        self.path = block.path\n",
    "        self.queueLatency = block.queueLatency  # total time acumulated in the queues\n",
    "        self.txLatency = block.txLatency  # total transmission time\n",
    "        self.propLatency = block.propLatency  # total propagation latency\n",
    "        self.totLatency = block.totLatency  # total latency\n",
    "\n",
    "\n",
    "def getReg(data, numbPaths, pathMetric, resultsPath, alpha, test_case, n_packets=200, get_cdf=True, printUnstable=False):\n",
    "    # split blocks into paths\n",
    "    paths = [[[] for _ in range(numbPaths)] for _ in range(numbPaths)]\n",
    "    latencies = np.zeros([numbPaths, numbPaths])\n",
    "    t_values = np.zeros([numbPaths, numbPaths])\n",
    "    p_values = []\n",
    "    isNotZero = np.zeros([numbPaths, numbPaths])\n",
    "\n",
    "    names = np.zeros(23)\n",
    "    for block in data:\n",
    "        name = block.ID.split(\"_\")\n",
    "        names[int(name[0])] = int(name[0])\n",
    "\n",
    "    done = False\n",
    "    i = 1\n",
    "    while not done:\n",
    "        if names[i] == 0:\n",
    "            names = np.delete(names, i)\n",
    "        else:\n",
    "            i += 1\n",
    "        if i >= len(names):\n",
    "            done = True\n",
    "\n",
    "    for block in data:\n",
    "        name = block.ID.split(\"_\")\n",
    "        paths[np.where(names == int(name[0]))[0][0]][np.where(names == int(name[1]))[0][0]].append(block)\n",
    "\n",
    "    print(\"Getting slope for {} gateways... \".format(numbPaths))\n",
    "    total_num_paths = 0\n",
    "    avg_totLatency = 0\n",
    "    avg_propLatency = 0\n",
    "    avg_txLatency = 0\n",
    "\n",
    "    for source in range(numbPaths):\n",
    "        for destination in range(numbPaths):\n",
    "            if paths[source][destination]:\n",
    "                lats = []\n",
    "\n",
    "                for block in paths[source][destination][-n_packets:]:\n",
    "                    lats.append(block.totLatency*1000)\n",
    "                    avg_propLatency += block.propLatency*1e3\n",
    "                    avg_txLatency += block.txLatency*1e3\n",
    "\n",
    "                total_num_paths+=1\n",
    "                reg = LinearRegression().fit(np.asarray([x for x in range(len(lats))]).reshape(-1, 1), np.asarray(lats))\n",
    "                latencies[source,destination] = reg.coef_[0]        # Slope\n",
    "                avg_totLatency += np.mean(lats)/(numbPaths*(numbPaths-1))\n",
    "                \n",
    "                s_x = np.sqrt(np.var(lats))\n",
    "                errs = 0\n",
    "                for latIndex, lat in enumerate(lats):\n",
    "                    errs += (lat - (reg.intercept_ + reg.coef_[0]*latIndex))**2\n",
    "                sigma2 = 1/(len(lats)-2) * errs\n",
    "                seBeta1 = np.sqrt(sigma2)/(s_x*np.sqrt(len(lats)))\n",
    "                if test_case ==\"two-sided\":\n",
    "                    t = np.abs(reg.coef_[0] - 0)/seBeta1\n",
    "                    p_value = 2*(1-scipy.stats.t.cdf(t,len(lats)-2))\n",
    "                    if t > scipy.stats.t.ppf(q=1-alpha/2,df=len(lats)-2):\n",
    "                        isNotZero[source,destination] = 1\n",
    "                elif test_case ==\"one-sided-lesser\":\n",
    "                    t = (reg.coef_[0] - 0)/seBeta1\n",
    "                    p_value = 1-scipy.stats.t.cdf(t,len(lats)-2)\n",
    "                    if t > scipy.stats.t.ppf(q=1-alpha,df=len(lats)-2):\n",
    "                        isNotZero[source,destination] = 1\n",
    "                else:    \n",
    "                    t = (reg.coef_[0] - 0)/seBeta1\n",
    "                    p_value = scipy.stats.t.cdf(t,len(lats)-2)\n",
    "                    if t < scipy.stats.t.ppf(q=alpha,df=len(lats)-2):\n",
    "                        isNotZero[source,destination] = 1\n",
    "                t_values[source,destination] = t\n",
    "                p_values.append(p_value)\n",
    "\n",
    "    if printUnstable:\n",
    "        print(np.nonzero(isNotZero))\n",
    "    avg_propLatency /= (total_num_paths*n_packets)\n",
    "    avg_txLatency /= (total_num_paths*n_packets)\n",
    "    avg_queueLatency = avg_totLatency - avg_propLatency-avg_txLatency\n",
    "    DF_t = pd.DataFrame(t_values)\n",
    "    DF_z = pd.DataFrame(isNotZero)\n",
    "    DF = pd.DataFrame(latencies)\n",
    "    DF_t.to_csv(resultsPath + \"t_blocks_{}.csv\".format(pathMetric,numbPaths))       # t_values\n",
    "    DF.to_csv(resultsPath + \"slope_blocks_{}.csv\".format(pathMetric,numbPaths))     # Slopes\n",
    "    DF_z.to_csv(resultsPath + \"nonZeroSlopes_blocks_{}.csv\".format(pathMetric,numbPaths))   # Test result\n",
    "\n",
    "    return np.sum(isNotZero), p_values, total_num_paths, np.array([avg_totLatency, avg_propLatency, avg_txLatency, avg_queueLatency])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_paths 2\n",
      "Getting slope for 2 gateways... \n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "Average latency is 64.589\n",
      "   total delay  prop_delay  transmission_delay  queue_delay\n",
      "2    64.588643   63.092358            0.867248     0.629036\n"
     ]
    }
   ],
   "source": [
    "pathMetric = \"Deep Q-Learning\"         # Choice between dataRate, latency, and Deep Q-Learning\n",
    "path = \"../Results/Congestion_test/{} 1.0/\".format(pathMetric)\n",
    "resultsPath = \"../Results/Congestion_test/Results/{} 1.0/\".format(pathMetric)\n",
    "\n",
    "# blocks_path = '../Results/Congestion_Test/Deep Q-Learning 1.0/blocks_2.npy'\n",
    "\n",
    "if not os.path.exists(resultsPath):\n",
    "    # Create a new directory because it does not exist\n",
    "    os.makedirs(resultsPath)\n",
    "\n",
    "significance_level = 0.05\n",
    "min_GWs = 2\n",
    "max_GWs = 3\n",
    "nonZeroes = []\n",
    "ratioNonZeroes = []\n",
    "average_latencies = np.zeros((max_GWs-min_GWs,4))\n",
    "test_type = \"one-sided-lesser\"\n",
    "p_values_vec = np.zeros((1,2))\n",
    "n_packets_for_regression = 200\n",
    "\n",
    "for numbGts in range(min_GWs,max_GWs):\n",
    "    data = np.load(path + \"blocks_{}.npy\".format(numbGts), allow_pickle=True)\n",
    "    print(\"no_paths {}\".format(numbGts))\n",
    "    numbNotZero, p_vals, no_paths, average_latencies[numbGts-min_GWs,:] = getReg(data,numbGts, pathMetric, resultsPath, significance_level, test_type, n_packets_for_regression, printUnstable=True)\n",
    "    print(\"Average latency is {:0.3f}\".format(average_latencies[numbGts-min_GWs,0]))\n",
    "    nonZeroes.append(numbNotZero)\n",
    "    ratioNonZeroes.append(numbNotZero/no_paths)\n",
    "    p_values_vec = np.vstack((p_values_vec,np.hstack((np.ones((no_paths,1))*numbGts,np.reshape(p_vals,(no_paths,1))))))\n",
    "DF = pd.DataFrame(nonZeroes, index=list(range(min_GWs,max_GWs)))\n",
    "DF.to_csv(resultsPath + \"numbNonZero.csv\")\n",
    "DF = pd.DataFrame(ratioNonZeroes, index=list(range(min_GWs,max_GWs)))\n",
    "DF.to_csv(resultsPath + \"ratioNonZero.csv\")\n",
    "DF_avg_lat = pd.DataFrame(average_latencies, index=list(range(min_GWs,max_GWs)), columns=['total delay','prop_delay','transmission_delay','queue_delay'])\n",
    "DF_avg_lat.to_csv(resultsPath + \"avgLatency.csv\")\n",
    "p_values_vec = np.delete(p_values_vec, 0, 0)\n",
    "np.savetxt(resultsPath + \"pVals.txt\", p_values_vec)\n",
    "print(DF_avg_lat)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SatNEx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
